\chapter{Operations}

\section{Basic Linear Algerba Subprograms (BLAS)}
As introduced in section \ref{sec:nd4jBlas}, BLAS defines the low-level routines for linear algebra operations (for vectors and matrices). Nd4j supports OpenBlas and Intel MKL as the CPU's libraries and Cuda (Cublas) as the GPU's library.

Those libraries are using a dense format only. In case of sparse we need to support two additional libraries: Intel MKL Sparse Blas and CuSparse. To be able to call the MKL sparse methods which are in the native side, we need to add its presets. The presets are generated by JavaCPP and define the signatures of each routines for which we need to bind it into a wrapper method in the java side.

BLAS is organized into three sets of routines called \textit{levels}:
\begin{description}
	\item [Level 1] performs scalar, vector and vector-vector operations (dot product, norm,\dots).
	\item [Level 2] performs matrix-vector operations (matrix-vector multiplication (gemv)).
	\item [Level 3] performs matrix-matrix operations (general matrix multiplication (gemm)).
\end{description} 
 
 All the operations are accessible through a BLAS wrapper of \textit{Nd4j}. They can be directly called via static methods or by calling them through an higher abstraction in \textit{INDArray} objects.
 
 This wrapper only wraps the methods of the dense BLAS library, this is why we need a specific wrapper for sparse BLAS library. However we want the different implementations to be transparent for the users, thus we use the dense wrapper as entry point and then redirect the call to the sparse wrapper internally. Thereby the user does not need to know the type of array is manipulating.
 
 A wrapper contains the implementations of each level and Lapack, which is a linear equation system resolver library. The \textit{Levels} interface define the set of operations for each level and then the implementations gather the the parameter and link to the JavaCPP presets and the native side.
 
 Similarly the sparse architecture has to have the same architecture: One sparse wrapper which contains the sparse implementation for each level.
 
 % TODO   -
 // TODO explain the architecture in nd4j?
\section{Backends}

Nd4j can run on the CPU or the GPU. 

It supports interchangeable backends. The API is the same, the differences between the backends are transparent for the user.
Each backend is parameter-able 

-- TODO : 


\subsection{In-Place Routines}
Some of the operations are performed in-place, that means the input matrix is modified during the operations.

We might have an issue when the number of non-null values increases. We could run out of space in the different buffers because the memory can not be reallocated from the native side and because we can not know how many new values will be added. To avoid this problem we have to ensure having enough space before performing the operations.

The solution is to allocate the maximum size that the routine could use to the \textit{DataBuffers}. At first it may look like inefficient and counterproductive according to the benefits we want to gain with the sparse implementation. However such operations are never executed on the whole array but only one a small sub-part of it.

\subsubsection{Example}
To illustrate this issue let's take an array $myArray$ with a size equals to $(100'000\times 100'000 \times 100)$. 
The following operation take a slice of the array $myArray$ (which corresponds in a row in this example) and assign $1.0$ to each value. 
\begin{lstlisting}
	myArray.get(NDIndexArray.point(0), 
		NDIndexArray.point(0), 
		NDIndexArray.all())
		.assign(1.0),
\end{lstlisting}
Despite the huge size of the array, we only add at most 100 new values. If the buffers have not the capacity to get this amount of new values, we need to reallocate them prior the operation.


\subsection{Level 1 Routines}

Sparse BLAS Level 1 routines in Intel MKL library \cite{mkllvl1} is a set of functions that perform vector operations on sparse vectors stored in a compressed format.	

The vector is represented in the compressed form by two arrays, \textit{values} and \textit{indexes}. Figure \ref{fig:compressedVector} shows how a vector is represented in that format.

\begin{figure}[h]
	\[
	\centering
	V_{(N\times 1)} = 
	\begin{bmatrix}
	a_{k_{0}}\\
	0\\
	a_{k_{1}}\\
	\dots\\
	a_{k_{NNZ}}
	\end{bmatrix}
	\quad\rightarrow\quad
	\begin{aligned}
		Value = 
		\begin{bmatrix}
		a_{k_{0}}& a_{{k_{1}}} & \dots & a_{k_{NNZ}}
		\end{bmatrix}\\
		Indexes = 
		\begin{bmatrix}
		k_{0} & k_{1} & \dots & k_{NNZ}		
		\end{bmatrix}
	\end{aligned}
	\]
	\caption{A vector $v$ and its compressed form representation}
	\label{fig:compressedVector}
\end{figure}


The \textit{values} array can be easily obtained from the CSR and COO format since it corresponds to the \textit{values} buffer in both representations.

In case of CSR vector the \textit{indexes} array corresponds to the column indexes buffer and can also be easily obtained.

However a value in a COO vector is always defined by two coordinates. It is due to a Nd4j singularity where the lowest possible rank for an array is 2, even in case of vector. The \textit{indexes} array has to be extract from the \textit{indexes} buffer depending whether it is a row vector or a column vector.

Once we get the two arrays, the procedure to call the BLAS routines is identical regardless of the underlying sparse format of the array. That mean we only need one implementation. The logic behind the arrays getters are implemented in the format-specific classes. 


\subsection{Level 2 and Level 3 Routines}

The level 2 routines perform operations between a sparse matrix and dense vectors whereas level 3 ones perform between a sparse matrix and dense matrices.

Intel MKL library supports several  sparse matrix storage formats such as COO and CSR and each type has its own implementation of the routines.

For now only the general matrix-vector product is implemented (Gemv) for the COO format. All the input parameters of the COO routines can be extracted by a \textit{SparseCOOGemvParameters} object which makes the future implementation of the level 2 routines easier.

\subsubsection{Gemv Routine}
This routine computes the matrix-vector product of a COO matrix and a dense vector. It can either compute $y = A*x$ or $y = A^{T}*x$ according to the parameter received in argument.

All the parameters needed to call the BLAS routine are extracted and computed according to the type of sparse format.
In case of COO, we need the an array of values, an array with the row indexes and an array with the column indexes. Since the indexes are flattened into one buffer, we split have to it into the two arrays.

\section{Libnd4j}
Most of the operations are implemented into libNd4j. Basically we used gemv and gemm from blas
..