\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}


Linear algebra forms the backbone of many machine learning algorithms, especially in deep learning. It provides structures such as vectors and matrices to hold the data and parameters to perform operations between them. Linear Algebra makes matrix operations fast and easy especially when training on GPUs.

Many of machine learning applications tend to deal with sparse dataset. Natural language processing applications, as stated by the Zips'f law, the frequency of any word in inversely proportional to its rank in the frequency table. ...

Typically in neural networks we have set of input organized into a vector on which we apply a collection of weights stored in matrices.  



