\chapter{The Deeplearning4j Library}

Deeplearning4j is a open-source Deep Learning library for the {JVM}. It runs on distributed CPU's and GPU's.

\section{Architecture of the library}
The library is composed by several sub-libraries:

\begin{description}[leftmargin=!,labelwidth=\widthof{\bfseries Deeplearning4j}]
	\item [Deeplearning4j] provides the tools to implement neural networks and build computation graphs
	\item [Nd4j] is the mathematical back-end of Deeplearning4j. It provides the data structures for the n-dimensional arrays and allow Java to access the native libraries via JavaCPP and the Java Native Interface.
	\item [Libnd4j] is the computing library that provides native operations on CPU and GPU. It's written in C++ and Cuda.
	\item [Datavec] provides the operations for the data processing such that data ingestion, normalization and transformation into feature vectors.
\end{description}


\section{The Importance of Nd4j in the Library}

Nd4j is at the base of the Deeplearning4j library, it provides data storage, manipulations, and operations. It gives the atomic pieces needed to build more complex deep learning systems such as neural networks.  Nd4j stands for N-Dimensional Arrays for Java and is basically a scientific computing library for the JVM. It features n-dimensional array object and the support of CPU and GPU via Cuda. 

The APIs provided by the library are essentially wrappers for the different version of BLAS (Basic Linear Algebra Subprogram). 

BLAS is  a specification that defines the low-level routines for linear algebra operations (for vectors and matrices). There exist several libraries implementing those subroutines in C or Fortran for dense or sparse formats. In Nd4j the BLAS subroutines can directly be called from Java thanks to JavaCPP, that internally uses the Java Native Interface (JNI) to call native routines from the JVM environment. This architecture allows the library to benefit from the advantages of the native side.

\section{Nd4j needs a Sparse Representation}

Currently in Deeplearning4j Sparse Data are treated like dense and use the dense operations of BLAS and Libnd4j to perform computations. With a new sparse representation we could gain in storage space and computation speed.
% -> develop 

